{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Discussion:\n",
    "## Large Scale GAN Training for High Fidelity Natural Image Synthesis#\n",
    "\n",
    "URL of original paper: https://arxiv.org/abs/1809.11096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can you guess which is generated?\n",
    "\n",
    "![g](./1809/images/neighbors/dog_pixel.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/syncedreview/biggan-a-new-state-of-the-art-in-image-synthesis-cf2ec5694024\n",
    "\n",
    "Colab demo: https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inception score:** The Inception Score is a metric for automatically evaluating the quality of image generative models\n",
    "\n",
    "$$\n",
    "\\text{IS} =\\exp(\\mathbb{E}_{x \\sim p_{g}}[DKL(p(y||x) || p(y))])\n",
    "$$\n",
    "\n",
    "where $x âˆ¼ p_g$ indicates that $x$ is an image sampled from $p_g$, $DKL(p||q)$ is the KL-divergence between the distributions $p$ and $q$, $p(y|x)$ is the conditional class distribution, and $p(y) = \\int_{x} p(y|x)p_g(x)$ is the marginal class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frechet Inception Distance(Score):** The FID is supposed to improve on the IS by actually comparing the statistics of generated samples to real samples, instead of evaluating generated samples in a vacuum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class embeddings:**\n",
    "\n",
    "Make the label the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Singular value:**\n",
    "\n",
    " Singular value decomposition is a factorization of a real or complex matrix (M):\n",
    " \n",
    " $$\n",
    " M = U \\Sigma V^*\n",
    " $$\n",
    " \n",
    "where $U$ and $V$ are real or complex unitary matrices and $\\Sigma$ is rectangular diagonal matrix with non-negative real numbers on the diagonal, the entries of which $\\sigma_{i}$ are known as the singular values.\n",
    "\n",
    "Singular vectors:\n",
    "\n",
    "$$\n",
    "    M\\vec{v} = \\sigma \\vec{u} \\quad \\text{and} \\quad M^{*} \\vec{u} = \\sigma \\vec{v}\n",
    "$$\n",
    "\n",
    "where $\\vec{u}$ and $\\vec{v}$ are the left-singular and right-singular vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spectral Normalization:** form a normalization that uses the first singular value of the weights matrix $W$ of each layer to replace the weights with:\n",
    "\n",
    "$$\n",
    "W \\to \\frac{W}{\\sigma(W)} \n",
    "$$\n",
    "\n",
    "See https://christiancosgrove.com/blog/2018/01/04/spectral-normalization-explained.html for a detailed explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Orthogonal Normalization:** enforces the orthogonality condition, see eq(2):\n",
    "\n",
    "$$\n",
    "R_{\\beta} = \\beta ||W^TW - I||_{F}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hinge loss:** for a prediction $y$ the hinge loss is\n",
    "\n",
    "$$\n",
    "l(y) = \\text{max}(0, 1 - t \\cdot y)\n",
    "$$\n",
    "\n",
    "where $t$ is the expected output $t = \\pm 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Orthogonal initialization:** Weights are initialized as random orthogonal matrices\n",
    "\n",
    "See: https://hjweide.github.io/orthogonal-initialization-in-convolutional-layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditional batch normaliztion:**\n",
    "\n",
    "$$\n",
    "z = \\gamma_s \\frac{x-\\mu}{\\sigma} \\beta_{s}\n",
    "$$\n",
    "\n",
    "See: http://arxiv.org/abs/1610.07629"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frobenius Norm** (Euclidean Norm):\n",
    "\n",
    "$$\n",
    "||A||_{f} = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}|a_{ij}|^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residual networks:**\n",
    "\n",
    "See: https://blog.waya.ai/deep-residual-learning-9610bb62c355"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: SAGAN\n",
    "\n",
    "https://medium.com/@jonathan_hui/gan-self-attention-generative-adversarial-networks-sagan-923fccde790c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images\n",
    "\n",
    "Additional images: https://drive.google.com/drive/folders/1lWC6XEPD0LT5KUnPXeve_kWeY-FxH002."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dog](./1809/images/rainbowdogs0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![td](./1809/images/badsamples/TennisBallDog.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
