---
layout: page
title: Suggested papers
permalink: /suggested-papers
---

Here's a list of papers that may be worth discussing at upcoming meetings sorted by general topics.

**Convolutional Neural Networks (CNNs)**
* [Attention Augmented Convolutional Networks](https://arxiv.org/abs/1904.09925)

**Generative Adverserial Networks (GANs)**
* [Generalization and Equilibrium in Generative Adversarial Nets (GANs)](https://arxiv.org/abs/1703.00573)
* [GauGAN: Semantic Image Synthesis with Spatially-Adaptive Normalization](https://arxiv.org/abs/1903.07291) + [blog post](https://blogs.nvidia.com/blog/2019/03/18/gaugan-photorealistic-landscapes-nvidia-research/)
* [Deblending galaxy superpositions with branched generative adversarial networks](https://arxiv.org/abs/1810.10098)
* [GAN Dissection: Visualizing and Understanding Generative Adversarial Networks](https://arxiv.org/abs/1811.10597v1) + [blog post](https://gandissect.csail.mit.edu/%E2%80%8B)
* [3D convolutional GAN for fast simulation](https://www.epj-conferences.org/articles/epjconf/abs/2019/19/epjconf_chep2018_02010/epjconf_chep2018_02010.html)

**Recurrent Neural Networks (RNN)**
* [Recurrent Attentive Neural Process for Sequential Data](https://arxiv.org/abs/1910.09323)

**Out-of-Distribution Detection**
* [Likelihood Ratios for Out-of-Distribution Detection](https://arxiv.org/abs/1906.02845)
* [Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network](https://dl.acm.org/doi/10.1145/3292500.3330672)
* [Normalizing flows for deep anomaly detection](http://arxiv.org/abs/1912.09323)

**Other**
* [WaveGlow: A Flow-based Generative Network for Speech Synthesis](https://arxiv.org/abs/1811.00002)
* [Training behavior of deep neural network in frequency domain](https://arxiv.org/abs/1807.01251)
* [Backward Feature Correction: How Deep Learning Performs Deep Learning](https://arxiv.org/abs/2001.04413)
* [Up to two billion times acceleration of scientific simulations with deep neural architecture search](https://arxiv.org/abs/2001.08055)


