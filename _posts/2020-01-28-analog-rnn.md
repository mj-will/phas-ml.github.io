---
layout: post
title:  "Wave Physics as an Analog Recurrent Neural Network"
date:   2020-01-28
categories: paper
speaker: Michael Williams
---

The paper discussed at this meeting presents theoretical model for developing analog recurrent neural networks based on wave equation. Whilst not directly applicable to most of our research, it highlights one of areas of machine learning research which is seeing increased development.

# Abstract

Analog machine learning hardware platforms promise to be faster and more energy-efficient than their digital counterparts. Wave physics, as found in acoustics and optics, is a natural candidate for building analog processors for time-varying signals. Here we identify a mapping between the dynamics of wave physics, and the computation in recurrent neural networks. This mapping indicates that physical wave systems can be trained to learn complex features in temporal data, using standard training techniques for neural networks. As a demonstration, we show that an inverse-designed inhomogeneous medium can perform vowel classification on raw audio signals as their waveforms scatter and propagate through it, achieving performance comparable to a standard digital implementation of a recurrent neural network. These findings pave the way for a new class of analog machine learning platforms, capable of fast and efficient processing of information in its native domain. 


The paper is available [here].

[here]: https://arxiv.org/abs/1904.12831
